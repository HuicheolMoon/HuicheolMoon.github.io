---
layout: post
title: "DL Basic : 3. Optimization"
category: DL
date: 2021-02-02 19:00:00 +0900
---
## Intro
>최적화와 관련된 주요한 용어와 다양한 Gradient Descent 기법들에 대하여 공부합니다.

## Optimization
최적화(Optimization)는 모델의 성능을 끌어올리는 작업을 의미합니다. Gradient Descent를 예로 든다면 value가 gradient를 따라 이동하면서 변하는 것을 parameter가 변화하면서 loss가 줄어드는 것으로 볼 수 있습니다. 모델의 Optimization에는 여섯 가지의 중요한 컨셉이 존재합니다.

### Generalization
Generalization은 우리가 학습시킨 모델의 효율이 얼마나 일정한지에 대한 것입니다. 모델이 학습 데이터에 대해 내놓은 결과가 일정하다고 하더라도 테스트 데이터에 대해 내놓은 결과가 아예 다른 것이라면 의미가 없습니다. 학습 데이터의 error와 테스트 데이터의 error 사이의 간극을 줄이는 것이 Generalization입니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108173048-f6f48e00-7140-11eb-8c26-3b88709b4edd.png" alt="Generalization"/>
  Generalization
</p>

### Under-fitting vs. Over-fitting
Under-fitting은 모델이 덜 학습되어서 결과를 제대로 나타내지 못하는 상태를 의미합니다. 반대로 Over-fitting은 모델이 과하게 학습되어서 학습 데이터에 대해서는 엄청난 효율을 가지지만 새로운 데이터에 대해서는 좋은 결과를 보이지 못하는 것을 의미합니다. 딥러닝 엔지니어는 모델이 두 상태로 빠지지 않게 적당히 학습을 조절해야 합니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108173252-420ea100-7141-11eb-8eec-e9975664adc9.png" alt="Under-fitting vs. Over-fitting"/>
  Under-fitting vs. Over-fitting
</p>

### Cross-validation
고정된 train set과 test set으로 모델을 학습하면 test set에만 Over-fitting 되어버릴 수 있습니다. 이를 위해서 Cross-validation이 필요합니다. Cross-validation은 기존의 train set을 k개로 나누어 각 부분을 test set으로 하는 학습을 여러 번 진행하고 다음으로 k개의 loss의 평균으로 모델의 성능을 평가하는 방법입니다.

### Bias-variance trade off
Bias는 결과가 어느 방향으로 치우치는 것을, Variance는 결과가 평균에서 퍼져있는 것을 의미합니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108173938-1fc95300-7142-11eb-8928-04bf55dcc9a4.png" alt="Bias and Variance"/>
  Bias and Variance
</p>

모든 경우에서 모델의 cost function은 bias의 제곱과 variance와 noise의 합으로 이루어져 있다는 것을 보일 수 있습니다. 즉, Bias와 variance 사이에는 필연적인 trade off 관계가 존재합니다. 그러므로 딥러닝 엔지니어는 항상 모델의 Bias와 variance를 적절히 조절하여 그 사이에서 균형을 찾아야 합니다.

### Bootstrapping
Bootstrapping은 어떤 test나 계산을 하기 전에 random sampling을 통하여 데이터를 선택하는 것을 말합니다. 데이터셋이 한정되어 데이터 분포가 고르지 않은 경우에 전체 데이터를 train set으로 학습하게 되면 모델은 major한 데이터에 focus하여 학습하게 됩니다. 이러한 모델은 test set에 대하여 잘 작동하기 힘듭니다. 이런 경우에 Bootstrapping을 사용하여 데이터의 분포를 평준화시키고 모델의 학습에 도움을 줄 수 있습니다.

### Bagging vs. Boosting
Bagging은 Bootstrapping aggregating의 약자로, Bootstrapping한 여러 개의 train set을 여러 개의 모델에 입력시켜 모델을 각각 학습시킨 후 모델을 다 합친 모델을 만드는 방법입니다. 결과의 variance을 감소시키는 역할을 합니다.

Boosting은 여러 개의 weak learner를 생성한 후 이 모델들을 sequence로 combine하여 이전 weak learner의 실수를 보강하는 것을 반복하는 모델을 만드는 방법입니다. 결과의 bias를 감소시키는 역할을 합니다.

## Gradient Descent Methods
Gradient Descent Methods에서 선험적으로 batch size가 커질수록 모델의 성능이 낮아진다고 합니다. Gradient Descent Methods는 method equation에 따라 여러 종류로 나뉩니다.

1. Stochastic gradient descent
    <p align="center">
      <img src="https://user-images.githubusercontent.com/77161691/108176186-0544a900-7145-11eb-8a88-c34650ecba0f.png" alt="Stochastic gradient descent"/>
      Stochastic gradient descent
    </p>

2. Momentum
    <p align="center">
      <img src="https://user-images.githubusercontent.com/77161691/108176289-2e653980-7145-11eb-87bf-ed339db26eb7.png" alt="Momentum"/>
      Momentum
    </p>

3. Nesterov accelerate dgradient
    <p align="center">
      <img src="https://user-images.githubusercontent.com/77161691/108176358-450b9080-7145-11eb-84b1-eb5704d94fb8.png" alt="Nesterov accelerate dgradient"/>
      Nesterov accelerate dgradient
    </p>

4. Adagrad
    <p align="center">
      <img src="https://user-images.githubusercontent.com/77161691/108176418-594f8d80-7145-11eb-9ec5-ffac07775270.png" alt="Adagrad"/>
      Adagrad
    </p>

5. Adadelta
    <p align="center">
      <img src="https://user-images.githubusercontent.com/77161691/108176478-6cfaf400-7145-11eb-82fb-a0c319737e52.png" alt="Adadelta"/>
      Adadelta
    </p>

6. RMSprop
    <p align="center">
      <img src="https://user-images.githubusercontent.com/77161691/108176546-83a14b00-7145-11eb-8061-ccc4447e23cc.png" alt="RMSprop"/>
      RMSprop
    </p>

7. Adam
    <p align="center">
      <img src="https://user-images.githubusercontent.com/77161691/108176615-9b78cf00-7145-11eb-8af1-57d9e0a81098.png" alt="Adam"/>
      Adam
    </p>

## Regularization
Regularization은 모델의 복잡도를 줄이는 것입니다. Regularization의 방법에는 여러 가지가 있습니다.

### Early Stopping
Early Stopping은 모델이 더 Overfitting되기 전에 학습을 종료하는 방법입니다. 모델을 만드는 초기 단계부터 계속 검증하면서 모델이 급격하게 복잡해지는 것을 막습니다. 이를 위해서는 모델의 복잡도를 검증하기 위한 validation data가 추가로 필요합니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108177202-44272e80-7146-11eb-85ed-bc22eef47009.png" alt="Early Stopping"/>
  Early Stopping
</p>

### Parameter norm penalty
Parameter norm penalty는 cost function 자체에 Parameter norm penalty term을 추가하여 parameter들이 너무 커지지 않게 하는 방법입니다.
<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108177522-b566e180-7146-11eb-83d9-999158853fce.png" alt="Parameter norm penalty"/>
  Parameter norm penalty
</p>

### Data augmentation
Data augmentation는 더욱 더 많은 데이터를 집어넣어 모델을 간단하면서도 효율적으로 만드는 방법입니다.

### Noise robustness
random한 noise input을 train set에 추가하는 방법입니다.

### Dropout
layer를 진행하면서 random으로 일부 neuron을 사용하지 않는 방법입니다.

<br/>

### References
1. NAVER Connect Foundation: Boostcamp AI Tech
