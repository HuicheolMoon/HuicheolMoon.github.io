---
layout: post
title: "AI Math : 11. Statistics"
category: DL
date: 2021-01-29 19:10:00 +0900
---
## Intro
>모수의 개념과 모수를 추정하는 방법인 최대가능도 추정법을 공부합니다.

## Parameter
머신러닝에서의 통계학은 적절한 가정 위에서 확률분포를 추정해야 합니다. 그러나 일부 데이터만 관찰해서 모집단의 분포를 정확하게 알아내는 것은 불가능하므로 근사적으로 확률분포를 추정할 수 밖에 없습니다. 그렇기에 우리는 데이터가 특정한 확률분포를 따른다고 가정한 후 그 분포를 결정하는 모수(parameter)를 추정하는 방법을 사용하게 됩니다. 데이터의 히스토그램과 범위에 따라 자주 사용되는 분포들이 존재합니다. 물론 데이터가 생성되는 원리를 고려하여 확률분포를 가정하는 것이 우선되어야 합니다.

|데이터|분포|
|---|:---:|
|0, 1|베르누이분포|
|n(X) = n|카테고리분포|
|[0,1]|베타분포|
|[0] + R+|감마분포, 로그정규분포|
|R|정규분포,라플라스분포|

## Maximum Likelihood Estimation
앞서 가정한 분포를 통해 관찰한 데이터의 표본평균과 표본분산을 구할 수 있습니다. 하지만 확률분포마다 사용하는 모수가 다르므로 적절한 통계량이 달라지게 됩니다. 이를 위해 최대가능도 추정법(maximum likelihood estimation, MLE)을 사용하게 됩니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108051469-47f77a00-708e-11eb-8863-ee54f6f2df72.png" alt="MLE"/>
  maximum likelihood estimation
</p>

데이터 집합이 독립적으로 추출된 경우에는 아래와 같이 로그가능도를 사용하게 됩니다. 이는 데이터의 수가 매우 많아질 경우에 미분연산의 시간복잡도를 줄이기 위함입니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108051701-8bea7f00-708e-11eb-99ed-85be659cabf3.png" alt="MLE with log-likelihood"/>
  maximum likelihood estimation with log
</p>

딥러닝에서는 모델이 학습하는 확률분포와 데이터에서 관찰되는 확률분포의 거리를 최소화시키는 방식으로 MLE를 사용합니다.

<br/>

### References
1. NAVER Connect Foundation: Boostcamp AI Tech
