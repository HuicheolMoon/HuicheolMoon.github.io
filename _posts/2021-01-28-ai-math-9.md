---
layout: post
title: "AI Math : 9. Probability Theory"
category: DL
date: 2021-01-28 19:10:00 +0900
---
## Intro
>확률분포, 조건부확률, 기대값의 개념과 몬테카를로 샘플링 방법에 대하여 공부합니다.

## Probability Theory
loss function은 해당 모델의 예측이 틀릴 위험을 최소화하는 방향으로 학습하도록 유도하는 역할을 가지고 있습니다. 이러한 risk의 분산 및 불확실성을 최소화하기 위해서는 이 수치들을 측정하는 방법을 아는 것이 필수적입니다.

## probability Distribution
확률변수는 확률분포에 따라 이산확률변수(discrete)와 연속확률변수(continuous)로 구분됩니다. 이산확률변수는 확률변수가 가질 수 있는 경우의 수를 모두 고려한 모델링이고, 연속확률변수는 데이터 공간에 정의된 확률변수의 밀도 위에
서의 적분을 통한 모델링입니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108048463-69566700-708a-11eb-94d1-6256744af7e4.png" alt="probability Distribution"/>
  probability Distribution
</p>

## Conditional Probability & Expectation
조건부확률(Conditional probability)은 주어진 사건이 일어났다는 가정 하에 다른 한 사건이 일어날 확률을 뜻합니다.

기댓값(Expectation)은 특정 확률분포에서 결과값으로 나올 수 있는 데이터의 평균을 의미합니다. 기대값을 이용해 분산, 첨도, 공분산 등 여러 통계량을 계산할 수 있습니다.

## Monte Carlo Sampling
많은 기계학습 문제들은 확률분포가 명시적이지 않습니다. 이러한 경우에 기댓값을 계산하기 위해서는 몬테카를로(Monte Carlo) 방법을 사용해야 합니다. 몬테카를로 방법은 충분히 많은 수의 반복 입력을 통해 나온 출력의 평균이 근사적으로 기대값에 한 없이 가까워 지는 성질을 이용한 것입니다. 몬테카를로 샘플링은 독립추출만 보장된다면 대수의 법칙(law of large number)에 의해 수렴성이 보장됩니다. 그 예시로 적분이 불가능한 아래의 함수에 대하여 몬테카를로 방법을 통해 적분값을 근사적으로 구할 수 있습니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108049377-863f6a00-708b-11eb-9dc1-fbc2daae4f1d.png" alt="Monte Carlo"/>
  Monte Carlo
</p>

<br/>

### References
1. NAVER Connect Foundation: Boostcamp AI Tech
