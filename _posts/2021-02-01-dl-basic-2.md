---
layout: post
title: "DL Basic : 2. Neural Networks & Multi-Layer Perceptron"
category: DL
date: 2021-02-01 19:30:00 +0900
---
## Intro
>신경망(Neural Networks)의 정의, Deep Neural Networks에 대해 공부합니다.

## Neural Networks
Neural Networks는 동물의 뇌를 구성하고 있는 생물학적인 구조에 영감을 받은 컴퓨팅 구조라고 할 수 있습니다. 하지만 Neural Networks가 뇌 구조와 유사한 것은 아닙니다. 초기의 비행기가 새와 유사할 형태이지만 현대의 비행기는 비행에 더 용이하게 형태가 변화하였듯이 Neural Networks 또한 문제를 처리하는 데에 최적화된 형태를 가지고 있습니다. 실제로 유명한 Neural Networks System인 GoogLeNet이나 ResNet의 diagram은 뇌와는 완전히 다른 형태를 가지고 있습니다.

문제 해결을 위해 단순히 Linear Neural Networks을 여러 층 stack하는 것은 그저 모든 layer의 matrix를 곱한 새로운 layer matrix 하나를 적용하는 것에 불과합니다. 문제 해결을 위해 각 layer를 최적화하기 위해서는 nonlinearity가 필요합니다. 이를 위한 장치가 바로 Activation function입니다. 예전에는 Sigmoid, tanh 등이 자주 사용되었고 최근에는 ReLU 등이 자주 사용되고 있습니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108045218-88eb9080-7086-11eb-89a2-ec0e1ed706c1.png" alt="activation function"/>
  Activation Function
</p>

## Multi-Layer Perceptron
Activation function을 이용하여 layer 사이에 nonlinearity를 추가한 구조를 Multi-Layer Perceptron이라고 합니다. 그리고 이 MLP를 문제에 최적화시키기 위해 MLP의 성능을 평가할 수단이 필요합니다. 이를 Loss functions이라고 합니다. 대개 loss의 최소화를 문제로 두고 MLP를 학습시키게 됩니다. Loss functions에는 MSE, CE, MLE 등이 자주 쓰이고 이 외에도 문제 해결을 위해 새로운 Loss functions을 정의할 수도 있습니다.

<br/>

### References
1. NAVER Connect Foundation: Boostcamp AI Tech
