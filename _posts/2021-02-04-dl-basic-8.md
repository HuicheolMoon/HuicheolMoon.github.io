---
layout: post
title: "DL Basic : 8. Transformer"
category: DL
date: 2021-02-04 19:20:00 +0900
---
## Intro
> Transformer에 대하여 공부합니다.

## Transformer
Sequential Model은 데이터의 일부가 소실되는 경우 치명적입니다. 이를 해결하기 위해서는 이러한 데이터의 변화를 고려할 수 있는 모델이 필요합니다. 이 것이 바로 Transformer입니다.

<p align="center">
  <img src="https://user-images.githubusercontent.com/77161691/108187988-64f58100-7152-11eb-83b3-58e5c81e45fc.png" alt="Transformer"/>
  Transformer
</p>

Transformer는 attention을 기반으로 한 first sequence transduction model입니다. Transformer는 encoder와 decoder로 이루어져있습니다. 그리고 encoder와 decoder 모두 Self-Attention 구조를 가집니다.

<br/>

### References
1. NAVER Connect Foundation: Boostcamp AI Tech
2. Attention Is All You Need, NIPS, Ashish et al.
